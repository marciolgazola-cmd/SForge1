#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# QUICK REFERENCE - Comandos de OtimizaÃ§Ã£o Synapse Forge
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ğŸ“Œ VERIFICAÃ‡ÃƒO RÃPIDA

## Status Geral
alias sforge-status='echo "ğŸ“Š Status Synapse Forge:" && echo "Ollama:" && pgrep -f "ollama serve" && echo "  âœ“ Rodando" || echo "  âœ— Parado" && echo "Streamlit:" && pgrep -f "streamlit" && echo "  âœ“ Rodando" || echo "  âœ— Parado" && nvidia-smi --query-gpu=name,memory.used,memory.total --format=csv,noheader'

## Verificar GPU
alias gpu-check='nvidia-smi --query-gpu=index,name,driver_version,compute_cap,memory.total,memory.used --format=csv,noheader'

## Verificar Modelos DisponÃ­veis
alias models-list='ollama list'

## Verificar CPU Threads
alias cpu-threads='cat /proc/cpuinfo | grep processor | wc -l'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸš€ INICIAR SERVIÃ‡OS

## Start Ollama (background)
alias ollama-start='nohup ollama serve > ~/.ollama/ollama.log 2>&1 &'

## Stop Ollama
alias ollama-stop='pkill -f "ollama serve"'

## Start Streamlit
alias streamlit-start='streamlit run cognitolink.py --server.port 8501 --logger.level=error &'

## Stop Streamlit
alias streamlit-stop='pkill -f streamlit'

## Start All Services
function start-sforge() {
    echo "ğŸš€ Iniciando Synapse Forge..."
    
    # Limpar pids antigos
    pkill -f "ollama serve" 2>/dev/null || true
    pkill -f streamlit 2>/dev/null || true
    sleep 1
    
    # Iniciar Ollama
    echo "  1/3 Ollama..."
    nohup ollama serve > ~/.ollama/ollama.log 2>&1 &
    sleep 3
    
    # Verificar
    if pgrep -f "ollama serve" > /dev/null; then
        echo "  âœ“ Ollama iniciado"
    else
        echo "  âœ— Ollama falhou"
        tail ~/.ollama/ollama.log
        return 1
    fi
    
    # Iniciar Streamlit
    echo "  2/3 Streamlit..."
    nohup streamlit run cognitolink.py --server.port 8501 > ~/.streamlit/streamlit.log 2>&1 &
    sleep 2
    
    if pgrep -f streamlit > /dev/null; then
        echo "  âœ“ Streamlit iniciado"
    else
        echo "  âœ— Streamlit falhou"
        tail ~/.streamlit/streamlit.log
        return 1
    fi
    
    echo "  3/3 Verificando conectividade..."
    sleep 2
    
    # Verificar GPU
    GPU_CHECK=$(nvidia-smi 2>/dev/null | grep -o "NVIDIA" || echo "GPU NOT FOUND")
    if [ "$GPU_CHECK" = "NVIDIA" ]; then
        echo "  âœ“ GPU detectada"
    fi
    
    # Teste Ollama
    TEST=$(curl -s http://localhost:11434/api/status | grep -o '"status"' || echo "FAIL")
    if [ "$TEST" = '"status"' ]; then
        echo "  âœ“ Ollama respondendo"
    else
        echo "  âœ— Ollama nÃ£o respondendo"
    fi
    
    echo ""
    echo "âœ… ServiÃ§os iniciados!"
    echo ""
    echo "ğŸŒ Acesso:"
    echo "   â€¢ Streamlit: http://192.168.15.20:8501"
    echo "   â€¢ Ollama API: http://localhost:11434"
    echo ""
}

## Stop All Services
function stop-sforge() {
    echo "ğŸ›‘ Parando Synapse Forge..."
    pkill -f "ollama serve" 2>/dev/null && echo "  âœ“ Ollama parado" || echo "  â€¢ Ollama jÃ¡ parado"
    pkill -f streamlit 2>/dev/null && echo "  âœ“ Streamlit parado" || echo "  â€¢ Streamlit jÃ¡ parado"
    echo "âœ… Tudo parado"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§ª TESTES

## Teste Ollama
function test-ollama() {
    echo "ğŸ§ª Testando Ollama..."
    
    MODEL=${1:-mixtral}
    
    echo "  Modelo: $MODEL"
    echo "  Enviando teste..."
    
    RESPONSE=$(curl -s -X POST http://localhost:11434/api/chat \
      -H "Content-Type: application/json" \
      -d "{
        \"model\": \"$MODEL\",
        \"messages\": [{\"role\": \"user\", \"content\": \"Diga 'Oi!' em uma palavra\"}],
        \"stream\": false
      }")
    
    if echo "$RESPONSE" | grep -q "message"; then
        echo "  âœ“ Resposta recebida"
        CONTENT=$(echo "$RESPONSE" | grep -o '"content":"[^"]*' | head -1 | cut -d'"' -f4)
        echo "  ğŸ“ Resposta: $CONTENT"
        return 0
    else
        echo "  âœ— Falha na resposta"
        echo "     $RESPONSE"
        return 1
    fi
}

## Teste Performance
function test-performance() {
    echo "ğŸ“Š Testando Performance..."
    
    MODEL=${1:-mixtral}
    ITERATIONS=${2:-3}
    
    echo "  Modelo: $MODEL"
    echo "  IteraÃ§Ãµes: $ITERATIONS"
    echo ""
    
    TOTAL_TIME=0
    
    for i in $(seq 1 $ITERATIONS); do
        echo "  Teste $i/$ITERATIONS..."
        START=$(date +%s%N)
        
        curl -s -X POST http://localhost:11434/api/chat \
          -H "Content-Type: application/json" \
          -d "{
            \"model\": \"$MODEL\",
            \"messages\": [{\"role\": \"user\", \"content\": \"Teste de latÃªncia $i\"}],
            \"stream\": false
          }" > /dev/null
        
        END=$(date +%s%N)
        ELAPSED=$(( (END - START) / 1000000 ))  # Converter ns â†’ ms
        ELAPSED_SEC=$(echo "scale=2; $ELAPSED / 1000" | bc)
        
        echo "    Tempo: ${ELAPSED_SEC}s"
        TOTAL_TIME=$(echo "$TOTAL_TIME + $ELAPSED_SEC" | bc)
    done
    
    AVG_TIME=$(echo "scale=2; $TOTAL_TIME / $ITERATIONS" | bc)
    echo ""
    echo "  ğŸ“ˆ Tempo mÃ©dio: ${AVG_TIME}s"
}

## Monitorar GPU em tempo real
function monitor-gpu() {
    echo "ğŸ“¡ Monitorando GPU (Ctrl+C para sair)..."
    watch -n 1 'nvidia-smi --query-gpu=index,name,utilization.gpu,utilization.memory,memory.used,memory.total --format=csv,noheader'
}

## Monitorar CPU/GPU
function monitor-system() {
    echo "ğŸ“¡ Monitorando Sistema (Ctrl+C para sair)..."
    watch -n 1 'echo "=== GPU ===" && nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader && echo "=== CPU ===" && top -bn1 | head -3'
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”§ MAINTENANCE

## Limpar cache Ollama
function clean-ollama-cache() {
    echo "ğŸ§¹ Limpando cache Ollama..."
    pkill -f "ollama serve" 2>/dev/null || true
    sleep 1
    rm -rf ~/.ollama/cache
    mkdir -p ~/.ollama/cache
    echo "âœ“ Cache limpo"
}

## Download modelo
function download-model() {
    MODEL=$1
    if [ -z "$MODEL" ]; then
        echo "âŒ Uso: download-model <model_name>"
        echo "   Exemplos: mixtral, llama2, neural-chat"
        return 1
    fi
    
    echo "ğŸ“¥ Baixando $MODEL..."
    ollama pull "$MODEL"
    echo "âœ“ Download concluÃ­do"
}

## Remover modelo
function remove-model() {
    MODEL=$1
    if [ -z "$MODEL" ]; then
        echo "âŒ Uso: remove-model <model_name>"
        return 1
    fi
    
    echo "ğŸ—‘ï¸  Removendo $MODEL..."
    ollama rm "$MODEL"
    echo "âœ“ Modelo removido"
}

## EspaÃ§o em disco
function disk-space() {
    echo "ğŸ’¾ Uso de EspaÃ§o:"
    du -sh ~/.ollama
    du -sh ~/.streamlit
    du -sh ~/.cache
    echo ""
    echo "ğŸ“Š EspaÃ§o disponÃ­vel:"
    df -h ~/.ollama | tail -1
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“– DOCUMENTAÃ‡ÃƒO

## Mostrar ajuda
function sforge-help() {
    cat << 'HELPEOF'
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸš€ SYNAPSE FORGE - QUICK REFERENCE v3.0                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ INICIAR/PARAR:
  start-sforge          - Iniciar todos os serviÃ§os
  stop-sforge           - Parar todos os serviÃ§os
  ollama-start/stop     - Controlar Ollama
  streamlit-start/stop  - Controlar Streamlit

ğŸ§ª TESTES:
  test-ollama [model]          - Testar resposta Ollama
  test-performance [model] [n] - Testar latÃªncia (n iteraÃ§Ãµes)
  monitor-gpu                  - Monitorar GPU em tempo real
  monitor-system               - Monitorar CPU + GPU

âš™ï¸  MANUTENÃ‡ÃƒO:
  download-model <name>   - Baixar novo modelo
  remove-model <name>     - Remover modelo
  clean-ollama-cache      - Limpar cache
  disk-space              - Ver uso de disco

âœ… STATUS:
  sforge-status    - Verificar status geral
  gpu-check        - Verificar GPU
  models-list      - Listar modelos disponÃ­veis
  cpu-threads      - Ver cores CPU

ğŸ“š DOCUMENTAÃ‡ÃƒO:
  cat OTIMIZACOES_v3_MIXTRAL.md  - Guia completo
  sforge-help                     - Esta ajuda

HELPEOF
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Mostrar ajuda ao carregar
echo "âœ… Synapse Forge Quick Commands Loaded!"
echo "   Execute: sforge-help"
